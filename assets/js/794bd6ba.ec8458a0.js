"use strict";(self.webpackChunkwebsite=self.webpackChunkwebsite||[]).push([[92408],{10707:(e,n,r)=>{r.r(n),r.d(n,{assets:()=>c,contentTitle:()=>l,default:()=>u,frontMatter:()=>o,metadata:()=>t,toc:()=>d});const t=JSON.parse('{"id":"users/faq/starlark_peak_mem","title":"Debugging Excess Starlark Peak Memory","description":"Wut memory?","source":"@site/../docs/users/faq/starlark_peak_mem.md","sourceDirName":"users/faq","slug":"/users/faq/starlark_peak_mem","permalink":"/docs/users/faq/starlark_peak_mem","draft":false,"unlisted":false,"tags":[],"version":"current","frontMatter":{"id":"starlark_peak_mem","title":"Debugging Excess Starlark Peak Memory"},"sidebar":"main","previous":{"title":"Common Issues","permalink":"/docs/users/faq/common_issues"},"next":{"title":"Why is Buck2 hanging?","permalink":"/docs/users/faq/buck_hanging"}}');var i=r(74848),a=r(28453),s=r(78191);const o={id:"starlark_peak_mem",title:"Debugging Excess Starlark Peak Memory"},l=void 0,c={},d=[{value:"Wut memory?",id:"wut-memory",level:2},{value:"How do I see my build file&#39;s peak memory usage?",id:"how-do-i-see-my-build-files-peak-memory-usage",level:2},{value:"Profiler to the rescue!",id:"profiler-to-the-rescue",level:2},{value:"How do I reduce memory footprint?",id:"how-do-i-reduce-memory-footprint",level:2},{value:"Repeatedly allocating memory unnecessarily in a loop",id:"repeatedly-allocating-memory-unnecessarily-in-a-loop",level:3},{value:"Simply allocating very big data-structures!",id:"simply-allocating-very-big-data-structures",level:3},{value:"Algorithmically inefficient code",id:"algorithmically-inefficient-code",level:3},{value:"Usage of inefficient library calls",id:"usage-of-inefficient-library-calls",level:3},{value:"Allocating for rare cases",id:"allocating-for-rare-cases",level:3},{value:"I still need more help!",id:"i-still-need-more-help",level:2}];function h(e){const n={a:"a",code:"code",h2:"h2",h3:"h3",p:"p",pre:"pre",strong:"strong",...(0,a.R)(),...e.components};return(0,i.jsxs)(i.Fragment,{children:[(0,i.jsx)(n.h2,{id:"wut-memory",children:"Wut memory?"}),"\n",(0,i.jsxs)(n.p,{children:["Peak memory is the maximum amount of memory used during evaluation of that\nparticular Starlark file. The memory is usually released after we finish the\nevaluation of the file. Because Starlark is only garbage collected in between\ntop-level statements in the BUCK file, but not garbage collected inside function\ncalls/macros, on large servers with 64 hardware threads (or more), memory usage\nmight accumulate, causing slowdowns or OOMs ",(0,i.jsxs)(s.FbInternalOnly,{children:[" or even SEVs (e.g.\nS372092). See\n",(0,i.jsx)(n.a,{href:"https://fb.workplace.com/groups/1267349253953900/permalink/1312921066063385/",children:"this post"}),"\nfor more details on how Starlark's current GC works "]})," ."]}),"\n",(0,i.jsxs)(n.p,{children:["To prevent such issues until proper GC is implemented, we have set a hard ",(0,i.jsx)(n.code,{children:"2GB"}),"\nmemory limit for Starlark's evaluation of build files. This is a per-file limit."]}),"\n",(0,i.jsx)(n.p,{children:"Note that this is different than the actual process memory which might include\nother things apart from Starlark\u2019s evaluation."}),"\n",(0,i.jsx)(n.h2,{id:"how-do-i-see-my-build-files-peak-memory-usage",children:"How do I see my build file's peak memory usage?"}),"\n",(0,i.jsxs)(n.p,{children:["To see the Starlark peak memory usage of a build file, you can inspect the event\nlog for your build file. Here is an example entry from the event log for buck2\nuquery ",(0,i.jsx)(n.code,{children:"target"})," showing that it uses 1.5GB:"]}),"\n",(0,i.jsx)(n.pre,{children:(0,i.jsx)(n.code,{className:"language-json",children:'{"Event":{..."data":{"Load":{"module_id":"target:BUCK","cell":"...","error":null,"starlark_peak_allocated_bytes":1610608640}}}}\n'})}),"\n",(0,i.jsx)(n.h2,{id:"profiler-to-the-rescue",children:"Profiler to the rescue!"}),"\n",(0,i.jsxs)(n.p,{children:["If you want to see more detailed breakdown where the memory is used, you should\nprofile Starlark's evaluation of build files. See\n",(0,i.jsx)(n.a,{href:"../../../rule_authors/optimization/#starlark-profiling",children:"this page"})," for details\nof profiling in the loading stage. This is a great starting point for\ntroubleshooting."]}),"\n",(0,i.jsx)(n.h2,{id:"how-do-i-reduce-memory-footprint",children:"How do I reduce memory footprint?"}),"\n",(0,i.jsxs)(n.p,{children:["There are many reasons why Starlark's evaluation of your build file might use a\nlot of memory. We list a few common cases below but there might be more\ncases.",(0,i.jsxs)(s.FbInternalOnly,{children:[" See\n",(0,i.jsx)(n.a,{href:"https://fb.workplace.com/groups/buck2eng/permalink/3309329642697846/",children:"this post"}),"\nfor a few real world examples of debugging Starlark peak memory usage of core\nAndroid macros that have saved over 5.7GB peak memory!"]})]}),"\n",(0,i.jsx)(n.p,{children:"High level guidance is to pay attention to loops as a starting point. Are there\nany unnecessary computations? Can you shave them off?"}),"\n",(0,i.jsx)(n.h3,{id:"repeatedly-allocating-memory-unnecessarily-in-a-loop",children:"Repeatedly allocating memory unnecessarily in a loop"}),"\n",(0,i.jsx)(n.p,{children:"A common case where memory usage might accumulate is repeatedly allocating\nmemory in a loop. For instance, below we call a memory intensive function in a\nloop unnecessarily:"}),"\n",(0,i.jsx)(n.pre,{children:(0,i.jsx)(n.code,{className:"language-python",children:"for target in huge_target_list:\n    memory_intensive_fun(x,y)\n    ...\n"})}),"\n",(0,i.jsxs)(n.p,{children:["Instead, if we know that arguments ",(0,i.jsx)(n.code,{children:"x"})," and ",(0,i.jsx)(n.code,{children:"y"})," don't change, we could hoist the\ncall to ",(0,i.jsx)(n.code,{children:"memory_intensive_fun"})," outside of the loop as follows:"]}),"\n",(0,i.jsx)(n.pre,{children:(0,i.jsx)(n.code,{className:"language-python",children:"memory_intensive_fun(x,y)\nfor target in huge_target_list:\n    ...\n"})}),"\n",(0,i.jsx)(n.h3,{id:"simply-allocating-very-big-data-structures",children:"Simply allocating very big data-structures!"}),"\n",(0,i.jsx)(n.p,{children:"Another reason why Starlark uses a lot of memory could simply be because the\nbuild file allocates a very big-data structure. For instance, below we allocate\na list with 1 billion integers!"}),"\n",(0,i.jsx)(n.pre,{children:(0,i.jsx)(n.code,{className:"language-python",children:"million_list = [1 for i in range(1 << 20)]\nbillion_list = million_list * (1 << 10)\n\n"})}),"\n",(0,i.jsx)(n.p,{children:"As a workaround, could you think of splitting the list?"}),"\n",(0,i.jsx)(n.h3,{id:"algorithmically-inefficient-code",children:"Algorithmically inefficient code"}),"\n",(0,i.jsx)(n.p,{children:"Another reason could be because memory efficiency of your code is bad, i.e. you\nare unnecessarily allocating a lot of memory. Let's look at an example where we\ntry to process a bunch of targets inefficiently:"}),"\n",(0,i.jsx)(n.pre,{children:(0,i.jsx)(n.code,{className:"language-python",children:"targets = generate_targets(n)\nfor target in targets:\n    process(target)\n"})}),"\n",(0,i.jsxs)(n.p,{children:["If ",(0,i.jsx)(n.code,{children:"targets"})," list is big ",(0,i.jsx)(n.strong,{children:"and"})," each target takes a lot of space in memory,\nmemory usage might exceed the limit. Instead, a more efficient version might be\nto process each target as you generate it:"]}),"\n",(0,i.jsx)(n.pre,{children:(0,i.jsx)(n.code,{className:"language-python",children:"for i in range(n):\n    target = generate_target(i)\n    process(target)\n"})}),"\n",(0,i.jsx)(n.p,{children:"In this version, each target is processed as it is generated so we never need to\nstore more than one target in memory."}),"\n",(0,i.jsx)(n.h3,{id:"usage-of-inefficient-library-calls",children:"Usage of inefficient library calls"}),"\n",(0,i.jsxs)(n.p,{children:["A more subtle reason could be unknowingly invoking library calls that allocate\neach time they are called. A well-known case of this is the ",(0,i.jsx)(n.code,{children:"dict.items()"})," call."]}),"\n",(0,i.jsx)(n.pre,{children:(0,i.jsx)(n.code,{className:"language-python",children:"for project, version in constraints.items():\n    # process each project ....\n"})}),"\n",(0,i.jsxs)(n.p,{children:["We do an allocation on every call to ",(0,i.jsx)(n.code,{children:"constraints.items()"}),". Especially if this\nis a hot code in Starlark, this could cause an OOM. Instead, a potential fix is\nto hoist the call out:"]}),"\n",(0,i.jsx)(n.pre,{children:(0,i.jsx)(n.code,{className:"language-python",children:"constraints = constraints.items()\nfor project, version in constraints:\n    # process each project ....\n"})}),"\n",(0,i.jsxs)(n.p,{children:["However, you need to ensure that the dictionary is not mutated inside, otherwise\nyou would get functionally different code. A similar case occurs for\n",(0,i.jsx)(n.code,{children:"dict.keys()"})," where it returns a new list for containing the keys."]}),"\n",(0,i.jsx)(n.h3,{id:"allocating-for-rare-cases",children:"Allocating for rare cases"}),"\n",(0,i.jsx)(n.p,{children:"Finally, another pattern is allocating memory for the rare cases. For instance,\nconsdier the following example"}),"\n",(0,i.jsx)(n.pre,{children:(0,i.jsx)(n.code,{className:"language-python",children:"for target in huge_target_list:\n    if memory_intensive_condition([target])\n        fail(...)\n"})}),"\n",(0,i.jsx)(n.p,{children:"Above program could be optimized as follows:"}),"\n",(0,i.jsx)(n.pre,{children:(0,i.jsx)(n.code,{className:"language-python",children:"if memory_intensive_condition(huge_target_list)\n    for target in huge_target_list:\n        if memory_intensive_condition([target])\n            fail(...)\n"})}),"\n",(0,i.jsx)(n.p,{children:"so that in the common non-failure case, we don't end up allocating excessive\nmemory."}),"\n",(0,i.jsx)(n.h2,{id:"i-still-need-more-help",children:"I still need more help!"}),"\n",(0,i.jsxs)(n.p,{children:["If you still can not figure out how to reduce Starlark memory footprint of your\nbuild files, ",(0,i.jsxs)(s.FbInternalOnly,{children:["please post in\n",(0,i.jsx)(n.a,{href:"https://fb.workplace.com/groups/buck2users",children:"Buck2 Users"})]}),(0,i.jsxs)(s.OssOnly,{children:["raise\n",(0,i.jsx)(n.a,{href:"https://github.com/facebook/buck2/issues",children:"an issue"})," in our Github\nproject"]}),"."]})]})}function u(e={}){const{wrapper:n}={...(0,a.R)(),...e.components};return n?(0,i.jsx)(n,{...e,children:(0,i.jsx)(h,{...e})}):h(e)}},28453:(e,n,r)=>{r.d(n,{R:()=>s,x:()=>o});var t=r(96540);const i={},a=t.createContext(i);function s(e){const n=t.useContext(a);return t.useMemo(function(){return"function"==typeof e?e(n):{...n,...e}},[n,e])}function o(e){let n;return n=e.disableParentContext?"function"==typeof e.components?e.components(i):e.components||i:s(e.components),t.createElement(a.Provider,{value:n},e.children)}}}]);