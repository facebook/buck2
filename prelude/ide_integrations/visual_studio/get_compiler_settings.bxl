# Copyright (c) Meta Platforms, Inc. and affiliates.
#
# This source code is dual-licensed under either the MIT license found in the
# LICENSE-MIT file in the root directory of this source tree or the Apache
# License, Version 2.0 found in the LICENSE-APACHE file in the root directory
# of this source tree. You may select, at your option, one of the
# above-listed licenses.

load("@prelude//cxx:cxx_toolchain_types.bzl", "CxxToolchainInfo")
load("@prelude//:paths.bzl", "paths")
load("flags_parser_utils.bxl", "flatten_flag_lists", "get_compiler_settings_from_flags")
load("get_attrs.bxl", "get_attrs")
load("utils.bxl", "dedupe_by_value", "dirname", "escape_xml", "get_argsfiles_output_path", "get_project_file_path", "h", "normcase", "normcase_backwards")

def _get_package_folder_relative_to_root(target: bxl.ConfiguredTargetNode, bxl_ctx) -> str:
    cell = target.label.cell
    package = target.label.package
    cell_map = bxl_ctx.audit().cell([cell, "root"])

    root_path = cell_map["root"].replace("\\", "/")
    cell_path = cell_map[cell].replace("\\", "/")

    result = paths.relativize(cell_path, root_path)
    if package:
        if result:
            result += "/"
        result += package

    return result

def _get_include_directories_from_attributes(target: bxl.ConfiguredTargetNode, attrs: dict, fields: list[str], bxl_ctx) -> list:
    package_folder_relative_to_root = _get_package_folder_relative_to_root(target, bxl_ctx)

    dirs = []
    for f in fields:
        dirs += attrs[f]

    dirs = [normcase("$(RepoRoot)\\" + package_folder_relative_to_root + "/" + d) for d in dirs]
    return dirs

def _get_additional_include_directories(target: bxl.ConfiguredTargetNode, attrs: dict, bxl_ctx) -> list:
    # Headers shall not be directly added to additional include directories.

    dirs = _get_include_directories_from_attributes(target, attrs, ["include_directories"], bxl_ctx)
    dirs = dedupe_by_value(dirs)

    return dirs


def _as_raw_header(
        label,
        # The full name used to include the header.
        name: str,
        header: Artifact):
    """
    Return path to pass to `include_directories` to treat the given header as
    a raw header.
    """
    name = paths.normalize(name)

    
    if not header.is_source:
        return None

    # To include the header via its name using raw headers and include dirs,
    # it needs to be a suffix of its original path, and we'll strip the include
    # name to get the include dir used to include it.
    path = paths.join(label.package, header.short_path)
    path = paths.normalize(path)
    base = paths.strip_suffix(path, name)
    if base == None:
        return None

    # If the include dir is underneath our package, then just relativize to find
    # out package-relative path.
    if len(base) >= len(label.package):
        return paths.relativize(base, label.package)

    # Otherwise, this include dir needs to reference a parent dir.
    num_parents = (
        len(label.package.split("/")) -
        (0 if not base else len(base.split("/")))
    )
    return "/".join([".."] * num_parents)


def _get_exported_additional_include_directories(target: bxl.ConfiguredTargetNode, attrs: dict, bxl_ctx) -> list:
    label = target.label

    # header_dirs is used in prebuilt_cxx_library (legacy Buck rule, still widely used for third-party code)
    # e.g., //third-party/gsl:gsl
    attr_fields = [
        "public_include_directories",
        "public_system_include_directories",
    ]

    dirs_by_attribute = _get_include_directories_from_attributes(target, attrs, attr_fields, bxl_ctx)
    dirs_by_attribute += [normcase_backwards(d) for d in attrs["header_dirs"]]

    dirs = []

    package_root = _get_package_folder_relative_to_root(target, bxl_ctx)
    for name, path in attrs["exported_headers"].items():
        if not "buck-out" in path:
            source_artifact = bxl_ctx.fs.source(path.replace("\\", "/"))
            as_raw = _as_raw_header(label, name, source_artifact)
            if as_raw != None:
                include_dir = package_root
                if as_raw:
                    include_dir += "/" + as_raw
                dirs.append(normcase_backwards(include_dir))
        else:
            # Header tree created by buck. This is the most correct form but depends on previous local build to materialize.
            # e.g.,
            # header: xplat/third-party/yajl:yajl  https://fburl.com/code/xqzlvuot
            # usage: xplat/mobileconfig/FBMobileConfigCore:FBMobileConfigCore  https://fburl.com/code/p4qw1cx3
            argsfiles_output_path = get_argsfiles_output_path(target, bxl_ctx)
            if argsfiles_output_path:
                include_dir = dirname(argsfiles_output_path) + "/buck-headers"
                dirs.append(normcase_backwards(include_dir))

    dirs = [normcase("$(RepoRoot)\\" + d) for d in dirs]
    return dedupe_by_value(dirs + dirs_by_attribute)

def _format_compiler_settings(compiler_settings: dict) -> dict:
    # Starlark passed in reference of dict. We don't want to accidentally override values, thus creating hard copy.
    concat_compiler_settings = dict(compiler_settings)

    concat_compiler_settings["AdditionalIncludeDirectories"] = ";".join(compiler_settings["AdditionalIncludeDirectories"] + ["%(AdditionalIncludeDirectories)"])
    concat_compiler_settings["AdditionalOptions"] = " ".join(compiler_settings["AdditionalOptions"] + ["%(AdditionalOptions)"])
    concat_compiler_settings["PreprocessorDefinitions"] = ";".join([escape_xml(s) for s in compiler_settings["PreprocessorDefinitions"]] + ["%(PreprocessorDefinitions)"])
    concat_compiler_settings["UndefinePreprocessorDefinitions"] = ";".join(compiler_settings["UndefinePreprocessorDefinitions"] + ["%(UndefinePreprocessorDefinitions)"])
    concat_compiler_settings["DisableSpecificWarnings"] = ";".join(compiler_settings["DisableSpecificWarnings"] + ["%(DisableSpecificWarnings)"])
    concat_compiler_settings["ForcedIncludeFiles"] = ";".join(compiler_settings["ForcedIncludeFiles"] + ["%(ForcedIncludeFiles)"])
    return concat_compiler_settings

def get_compiler_settings(target: bxl.ConfiguredTargetNode, attrs: dict, bxl_ctx) -> dict:
    """return private compiler settings to be written to .vcxproj for given buck target"""
    compiler_flags = flatten_flag_lists(attrs["preprocessor_flags"] + attrs["compiler_flags"])
    compiler_settings = get_compiler_settings_from_flags(compiler_flags)
    compiler_settings["AdditionalIncludeDirectories"].extend(_get_additional_include_directories(target, attrs, bxl_ctx))

    return compiler_settings

def get_exported_compiler_settings(target: bxl.ConfiguredTargetNode, attrs: dict, bxl_ctx) -> dict:
    """return exported compiler settings that propogate to transitive dependants"""
    exported_compiler_flags = flatten_flag_lists(attrs["exported_preprocessor_flags"])
    exported_compiler_settings = get_compiler_settings_from_flags(exported_compiler_flags)
    exported_compiler_settings["AdditionalIncludeDirectories"].extend(_get_exported_additional_include_directories(target, attrs, bxl_ctx))

    return exported_compiler_settings

def gen_compiler_settings(compiler_settings: dict):
    concat_compiler_settings = _format_compiler_settings(compiler_settings)
    return h(
        "ClCompile",
        [
            h(key, value, indent_level = 3)
            for key, value in concat_compiler_settings.items()
        ],
        {
            "Label": "CompilerSettings",
        },
        indent_level = 2,
    )

def materialize_compiler_settings_file(target_node, actions, cxx_toolchain_info, bxl_ctx):
    attrs = get_attrs(target_node, bxl_ctx)

    cxxflags_artifact = None
    if cxx_toolchain_info:
        cxxflags_artifact, _ = actions.write(get_project_file_path(target_node.label, ".cxxflags"), cxx_toolchain_info.cxx_compiler_info.compiler_flags, allow_args = True)

    attrs_outfile = actions.write_json(get_project_file_path(target_node.label, ".attrs.json"), attrs, pretty = True)
    out = actions.declare_output(get_project_file_path(target_node.label, ".compiler_settings.json"))

    def f(ctx, artifacts, outputs, attrs_outfile = attrs_outfile, out = out, target = target_node):
        attrs_input = artifacts[attrs_outfile].read_json()
        settings = {}

        if cxx_toolchain_info:
            cxxflags = artifacts[cxxflags_artifact].read_string().splitlines()
            exported_compiler_settings = get_compiler_settings_from_flags(cxxflags)
        else:
            exported_compiler_settings = get_exported_compiler_settings(target, attrs_input, ctx)

        settings["compiler_settings"] = get_compiler_settings(target_node, attrs_input, ctx)
        settings["exported_compiler_settings"] = exported_compiler_settings

        ctx.bxl_actions().actions.write_json(outputs[out].as_output(), settings, pretty = True)

    dynamic = [attrs_outfile]
    if cxxflags_artifact:
        dynamic.append(cxxflags_artifact)

    actions.dynamic_output(
        dynamic = dynamic,
        inputs = [],
        outputs = [out.as_output()],
        f = f,
    )

    return out

def _main(bxl_ctx):
    target = bxl_ctx.cli_args.target
    target_node = bxl_ctx.configured_targets(target)
    actions = bxl_ctx.bxl_actions().actions

    cxx_toolchain_analysis_result = bxl_ctx.analysis(target_node)
    cxx_toolchain_info = cxx_toolchain_analysis_result.providers().get(CxxToolchainInfo)

    out = materialize_compiler_settings_file(target_node, actions, cxx_toolchain_info, bxl_ctx)
    bxl_ctx.output.print(bxl_ctx.output.ensure(out))

main = bxl_main(
    impl = _main,
    cli_args = {
        "log_level": cli_args.int(default = 30),
        "target": cli_args.target_label(),
    },
)
