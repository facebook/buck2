# Copyright (c) Meta Platforms, Inc. and affiliates.
#
# This source code is licensed under both the MIT license found in the
# LICENSE-MIT file in the root directory of this source tree and the Apache
# License, Version 2.0 found in the LICENSE-APACHE file in the root directory
# of this source tree.

load("@prelude//linking:link_info.bzl", "LinkStrategy")
load("@prelude//rust:build_params.bzl", "MetadataKind")
load("@prelude//rust:link_info.bzl", "RustLinkInfo")
load("@prelude//utils:set.bzl", "set")
load("@prelude//utils:type_defs.bzl", "is_list")

TargetInfo = dict[str, typing.Any]

MacroOutput = record(
    actual = TargetLabel,
    dylib = bxl.EnsuredArtifact,
)

ExpandedAndResolved = record(
    expanded_targets = list[TargetLabel],
    queried_proc_macros = dict[TargetLabel, MacroOutput],
    resolved_deps = dict[TargetLabel, TargetInfo],
)

MappedSrc = record(
    target = bxl.ConfiguredTargetNode,
    src = Label,
    dest = str,
)

def materialize(
        ctx: BxlContext,
        target: bxl.ConfiguredTargetNode) -> bxl.EnsuredArtifact:
    analysis = ctx.analysis(target)
    sources = analysis.providers()[DefaultInfo].sub_targets["sources"][DefaultInfo].default_outputs[0]

    # Ensures the srcs folder will be present
    return ctx.output.ensure(sources).abs_path()

def _process_target_config(
        ctx: BxlContext,
        target: bxl.ConfiguredTargetNode,
        analysis: bxl.AnalysisResult,
        in_workspace: bool) -> TargetInfo:
    providers = analysis.providers()

    # convert all source paths to absolute paths
    resolved_attrs = target.resolved_attrs_eager(ctx)

    # Using srcs instead of .sources() gives the resolved artifacts if provided with a buck rule as a src label.
    # For example, this is used in cxx powered crates internally
    srcs = []
    for src in resolved_attrs.srcs:
        srcs.append(ctx.output.ensure(src).abs_path())

    # remove the configured platform from the deps. for example,
    # `fbsource//third-party/rust:tracing (ovr_config//platform/linux:x86_64-fbcode-platform010-clang-9f23200ddcddc3cb)`
    # becomes `fbsource//third-party/rust:tracing`.
    deps = []
    for dep in resolved_attrs.deps:
        deps.append(dep.label.raw_target())

    # Grab only the values that the the gen-rules are being mapped to.
    mapped_srcs = {}
    for key, v in resolved_attrs.mapped_srcs.items():
        mapped_srcs[v] = ctx.output.ensure(key).abs_path()

    # remove the configured platform from named deps.
    if is_list(resolved_attrs.named_deps):
        named_deps_names = providers[DefaultInfo].sub_targets["named_deps"][DefaultInfo].default_outputs[0]
        named_deps = [ctx.output.ensure(named_deps_names).abs_path()]
        for _alias, dep in resolved_attrs.named_deps:
            named_deps.append(dep.label.raw_target())
    else:
        named_deps = {}
        for dep, alias in resolved_attrs.named_deps.items():
            named_deps[dep] = alias.label.raw_target()

    # remove the configured platform for tests
    tests = []
    for test in resolved_attrs.tests:
        tests.append(test.raw_target())

    # materialize a file containing the dynamic crate name
    crate_dynamic = getattr(resolved_attrs, "crate_dynamic", None)
    if crate_dynamic:
        cratename_artifact = crate_dynamic.get(DefaultInfo).default_outputs[0]
        crate_dynamic = ctx.output.ensure(cratename_artifact).abs_path()

    # copy over the absolute paths and raw targets into the output
    copy = {}
    attrs = target.attrs_eager()
    for k in dir(attrs):
        if k == "srcs":
            copy["srcs"] = srcs
        elif k == "deps":
            copy["deps"] = deps
        elif k == "mapped_srcs":
            copy["mapped_srcs"] = mapped_srcs
        elif k == "named_deps":
            copy["named_deps"] = named_deps
        elif k == "tests":
            copy["tests"] = tests
        elif k == "crate_dynamic":
            copy["crate_dynamic"] = crate_dynamic
        else:
            copy[k] = getattr(attrs, k)

    # Always generate the source folder. Let rust-project resolve whether or not to use it
    copy["source_folder"] = materialize(ctx, target)
    copy["label"] = target.label.raw_target()
    copy["project_relative_buildfile"] = ctx.fs.project_rel_path(target.buildfile_path)
    copy["kind"] = target.rule_type
    copy["in_workspace"] = in_workspace

    return copy

def cquery_deps(
        ctx: BxlContext,
        top_targets: list[TargetLabel],
        workspaces: list[TargetLabel],
        actions: AnalysisActions) -> dict[TargetLabel, TargetInfo]:
    target_universe = ctx.target_universe(top_targets).target_set()
    targets = ctx.cquery().deps(target_universe)
    outputs = ctx.cquery().kind("^(rust_binary|rust_library|rust_test)$", targets)
    out = {}

    # Eagerly analyze targets
    analysis = ctx.analysis(outputs)

    mapped_srcs = []
    seen = {}
    for target in outputs:
        attrs = target.attrs_lazy()

        in_workspace = target.label.raw_target() in top_targets
        for candidate_workspace in attrs.get("_workspaces").value():
            if candidate_workspace.raw_target() in workspaces:
                in_workspace = True

        target_info = _process_target_config(
            ctx = ctx,
            target = target,
            analysis = analysis[target.label.with_sub_target()],
            in_workspace = in_workspace,
        )

        labels = attrs.get("labels")
        if "thrift_library-rust" in labels.value():
            for src, dest in attrs.get("mapped_srcs").value().items():
                mapped_srcs.append(MappedSrc(
                    target = target,
                    src = src,
                    dest = dest,
                ))
        elif "generated_protobuf_library_rust" in labels.value():
            protobuf_out_dir = materialize_generated_protobufs(ctx, target, actions, seen)
            target_info["out_dir"] = protobuf_out_dir

        out[target.label.raw_target()] = target_info

    materialize_generated_thrift(ctx, actions, mapped_srcs, out)

    return out

def materialize_generated_protobufs(
        ctx: BxlContext,
        target: bxl.ConfiguredTargetNode,
        actions: AnalysisActions,
        seen: dict[str, bxl.EnsuredArtifact]) -> bxl.EnsuredArtifact:
    """If `target` has a dependency that generates code from protobufs,
    materialize the generated code and return the path to the output directory.
    """
    named_deps = target.attrs_lazy().get("named_deps").value()
    prost_target = dict(named_deps).get("generated_prost_target")
    t = prost_target.raw_target()
    analysis = ctx.analysis(t)
    output = analysis.providers()[DefaultInfo].default_outputs[0]
    outfile = "{}/{}/{}".format(t.cell, t.package, t.name)

    artifact = seen.get(outfile)
    if not artifact:
        artifact = ctx.output.ensure(actions.copy_file(outfile, output))
        seen[outfile] = artifact

    return artifact.abs_path()

def materialize_generated_thrift(
        ctx: BxlContext,
        actions: AnalysisActions,
        mapped_srcs: list[MappedSrc],
        out: dict[TargetLabel, TargetInfo]) -> None:
    built = ctx.build([m.src for m in mapped_srcs])

    seen = {}
    for m in mapped_srcs:
        build_result = built[m.src]
        if len(build_result.artifacts()) == 0:
            continue

        outfile = "{}/{}/{}/{}".format(m.target.label.cell, m.target.label.package, m.target.label.name, m.dest)

        artifact = seen.get(outfile)
        if not artifact:
            copied = actions.copy_file(outfile, build_result.artifacts()[0])
            artifact = ctx.output.ensure(copied)
            seen[outfile] = artifact

        if m.dest == "lib.rs":
            out[m.target.label.raw_target()]["crate_root"] = artifact.abs_path()

def expand_proc_macros(
        ctx: BxlContext,
        targets: list[TargetLabel]) -> dict[TargetLabel, MacroOutput]:
    target_universe = ctx.target_universe(targets).target_set()
    targets = ctx.cquery().deps(target_universe)
    targets = ctx.cquery().kind("^(rust_binary|rust_library)$", targets)

    out = {}
    for target in targets:
        attrs = target.resolved_attrs_eager(ctx)
        proc_macro = getattr(attrs, "proc_macro", False)
        if proc_macro:
            analysis = ctx.analysis(target)
            rlib = analysis.providers()[RustLinkInfo].strategies[LinkStrategy("shared")].outputs[MetadataKind("link")]
            label = target.label.raw_target()
            out[label] = MacroOutput(
                actual = label,
                dylib = ctx.output.ensure(rlib).abs_path(),
            )
    return out

# Returns a list of all the expanded targets including any workspaces, followed by just the workspaces
def expand_targets(
        ctx: BxlContext,
        targets: list[TargetLabel]) -> (list[TargetLabel], list[TargetLabel]):
    target_universe = ctx.target_universe(targets).target_set()
    kind_target_list = ctx.cquery().kind("^(rust_binary|rust_library|rust_test|alias)$", target_universe)

    # Allow targets to opt-in to being treated as rust-analyzer-compatible.
    # This is used for cross-compilation targets that apply Buck transitions to Rust rules.
    labeled_target_list = ctx.cquery().attrfilter("labels", "rust_analyzer_target", target_universe)
    expanded_targets = {t.label.raw_target(): t for t in kind_target_list + labeled_target_list}

    # Map of potential workspaces to a list of the targets that name these as potential workspaces
    possible_workspaces = {}
    for label, t in expanded_targets.items():
        workspaces = t.attrs_lazy().get("_workspaces")
        if workspaces:
            for workspace in workspaces.value():
                if not ctx.target_exists(str(workspace.raw_target())):
                    continue

                possible_workspaces.setdefault(workspace.raw_target(), []).append(label)

    active_workspaces = {}
    for workspace, candidate_deps in possible_workspaces.items():
        # FIXME: Using `cquery deps` here is not right. It will transparently look through
        # dependency edges of all types, meaning that eg build tools written in Rust and built
        # from source will show up too
        workspace_deps = {d.label.raw_target(): () for d in ctx.cquery().deps(workspace)}
        for d in candidate_deps:
            if d in workspace_deps:
                active_workspaces[workspace] = ()

                # Remove the target from the expanded targets. This is correct because we know
                # that the target will reappear later as a dep of the workspace. To understand why
                # it's necessary, consider the case where the target is a proc macro: Later doing
                # cquery deps(proc_macro + workspace) will result in the proc macro appearing twice,
                # once in its exec configuration and once in its target configuration
                # FIXME: Add a test for this. It's currently a bit hard to test because proc macros
                # in the prelude are a bit hard in general
                expanded_targets.pop(d, None)

    return dedupe(sorted(expanded_targets.keys() + active_workspaces.keys())), sorted(active_workspaces.keys())

def expand_and_resolve_impl(ctx: BxlContext) -> None:
    # equivalent of `flat_map`ing
    targets = [target for sublist in ctx.cli_args.targets for target in sublist]
    actions = ctx.bxl_actions().actions

    expanded_targets, workspaces = expand_targets(ctx, targets)
    queried_proc_macros = expand_proc_macros(ctx, expanded_targets)
    resolved_deps = cquery_deps(ctx, expanded_targets, workspaces, actions)

    ctx.output.print_json(ExpandedAndResolved(
        expanded_targets = expanded_targets,
        queried_proc_macros = queried_proc_macros,
        resolved_deps = resolved_deps,
    ))

def resolve_owning_buildfile_impl(ctx: BxlContext) -> None:
    max_extra_targets = ctx.cli_args.max_extra_targets

    if ctx.cli_args.files:
        targets = ctx.uquery().owner(ctx.cli_args.files)
    elif ctx.cli_args.buildfiles:
        targets = [ctx.uquery().targets_in_buildfile(buildfile) for buildfile in ctx.cli_args.buildfiles]

        # equivalent of `flat_map`ing
        targets = [target for sublist in targets for target in sublist]
        targets = ctx.uquery().kind("^(rust_binary|rust_library|rust_test)$", targets)
    elif ctx.cli_args.targets:
        # equivalent of `flat_map`ing
        targets = [target for sublist in ctx.cli_args.targets for target in sublist]
        targets = ctx.unconfigured_targets(targets)
    else:
        fail("`--files`, `--targets`, nor `--buildfiles` where specified; this is a bug")

    out = {}

    for target in targets:
        rust_targets = set()
        buildfile = "{}".format(target.buildfile_path)

        buildfile_path = ctx.fs.abs_path_unsafe(target.buildfile_path)
        if buildfile_path in out:
            continue
        rust_targets.add(target.label)

        targets_in_buildfile = ctx.uquery().targets_in_buildfile(buildfile)
        extra_rust_targets = ctx.uquery().kind("^(rust_binary|rust_library|rust_test)$", targets_in_buildfile)
        for t in extra_rust_targets:
            rust_targets.add(t.label)

        out[buildfile_path] = rust_targets.list()[:max_extra_targets]

    ctx.output.print_json(out)

expand_and_resolve = bxl_main(
    impl = expand_and_resolve_impl,
    cli_args = {
        "targets": cli_args.list(cli_args.target_expr()),
    },
)

resolve_owning_buildfile = bxl_main(
    impl = resolve_owning_buildfile_impl,
    cli_args = {
        # while buildfiles, files, and targets can all be passed, only files will be used.
        # this file is driven primarily by rust-project's needs and is a private implementation
        # detail.
        "buildfiles": cli_args.option(cli_args.list(cli_args.string())),
        "files": cli_args.option(cli_args.list(cli_args.string())),
        "max_extra_targets": cli_args.int(),
        "targets": cli_args.option(cli_args.list(cli_args.target_expr())),
    },
)
