# Copyright (c) Meta Platforms, Inc. and affiliates.
#
# This source code is licensed under both the MIT license found in the
# LICENSE-MIT file in the root directory of this source tree and the Apache
# License, Version 2.0 found in the LICENSE-APACHE file in the root directory
# of this source tree.

load("@prelude//linking:link_info.bzl", "LinkStrategy")
load("@prelude//rust:link_info.bzl", "RustLinkInfo")

def materialize(ctx, target):
    analysis = ctx.analysis(target)
    sources = analysis.providers()[DefaultInfo].sub_targets["sources"][DefaultInfo].default_outputs[0]

    # Ensures the srcs folder will be present
    return ctx.output.ensure(sources).abs_path()

def _process_target_config(ctx, target, in_workspace, out_dir = None):
    # convert all source paths to absolute paths
    resolved_attrs = target.resolved_attrs_eager(ctx)

    # Using srcs instead of .sources() gives the resolved artifacts if provided with a buck rule as a src label.
    # For example, this is used in cxx powered crates internally
    srcs = []
    for src in resolved_attrs.srcs:
        srcs.append(ctx.output.ensure(src).abs_path())

    # remove the configured platform from the deps. for example,
    # `fbsource//third-party/rust:tracing (ovr_config//platform/linux:x86_64-fbcode-platform010-clang-9f23200ddcddc3cb)`
    # becomes `fbsource//third-party/rust:tracing`.
    deps = []
    for dep in resolved_attrs.deps:
        deps.append(dep.label.raw_target())

    # Grab only the values that the the gen-rules are being mapped to.
    mapped_srcs = {}
    for key, v in resolved_attrs.mapped_srcs.items():
        mapped_srcs[v] = ctx.output.ensure(key).abs_path()

    # remove the configured platform from named deps.
    named_deps = {}
    for dep, alias in resolved_attrs.named_deps.items():
        named_deps[dep] = alias.label.raw_target()

    # remove the configured platform for tests
    tests = []
    for test in resolved_attrs.tests:
        tests.append(test.raw_target())

    # materialize a file containing the dynamic crate name
    crate_dynamic = getattr(resolved_attrs, "crate_dynamic", None)
    if crate_dynamic:
        cratename_artifact = crate_dynamic.get(DefaultInfo).default_outputs[0]
        crate_dynamic = ctx.output.ensure(cratename_artifact).abs_path()

    # copy over the absolute paths and raw targets into the output
    copy = {}
    attrs = target.attrs_eager()
    for k in dir(attrs):
        if k == "srcs":
            copy["srcs"] = srcs
        elif k == "deps":
            copy["deps"] = deps
        elif k == "mapped_srcs":
            copy["mapped_srcs"] = mapped_srcs
        elif k == "named_deps":
            copy["named_deps"] = named_deps
        elif k == "tests":
            copy["tests"] = tests
        elif k == "crate_dynamic":
            copy["crate_dynamic"] = crate_dynamic
        else:
            copy[k] = getattr(attrs, k)

    # Always generate the source folder. Let rust-project resolve whether or not to use it
    copy["source_folder"] = materialize(ctx, target)
    copy["label"] = target.label.raw_target()
    copy["project_relative_buildfile"] = ctx.fs.project_rel_path(target.buildfile_path)
    copy["kind"] = target.rule_type
    copy["in_workspace"] = in_workspace
    if out_dir:
        copy["out_dir"] = out_dir

    return copy

def cquery_deps(ctx, top_targets, workspaces, actions):
    target_universe = ctx.target_universe(top_targets).target_set()
    targets = ctx.cquery().deps(target_universe)
    outputs = ctx.cquery().kind("^(rust_binary|rust_library|rust_test)$", targets)
    out = {}

    # Eagerly analyze targets
    ctx.analysis(outputs)

    seen = {}
    for target in outputs:
        in_workspace = target.label.raw_target() in top_targets
        for candidate_workspace in target.attrs_lazy().get("_workspaces").value():
            if candidate_workspace.raw_target() in workspaces:
                in_workspace = True

        labels = target.attrs_lazy().get("labels")
        if "thrift_library-rust" in labels.value():
            thrift_files = materialize_generated_thrift(ctx, target, actions, seen)
            cfg = _process_target_config(ctx, target, in_workspace)
            for thrift in thrift_files:
                if thrift["mapped_src"] == "lib.rs":
                    cfg["crate_root"] = thrift["artifact"]
            out[target.label.raw_target()] = cfg
        elif "generated_protobuf_library_rust" in labels.value():
            protobuf_out_dir = materialize_generated_protobufs(ctx, target, actions, seen)
            out[target.label.raw_target()] = _process_target_config(ctx, target, in_workspace, protobuf_out_dir)
        else:
            out[target.label.raw_target()] = _process_target_config(ctx, target, in_workspace)
    return out

def materialize_generated_protobufs(ctx, target, actions, seen):
    """If `target` has a dependency that generates code from protobufs,
    materialize the generated code and return the path to the output directory.
    """
    prost_target = target.attrs_lazy().get("named_deps").value().get("generated_prost_target")
    t = prost_target.raw_target()
    analysis = ctx.analysis(t)
    output = analysis.providers()[DefaultInfo].default_outputs[0]
    outfile = "{}/{}/{}".format(t.cell, t.package, t.name)

    if outfile in seen:
        return None
    seen[outfile] = ()

    copied = ctx.output.ensure(actions.copy_file(outfile, output))
    return copied.abs_path()

def materialize_generated_thrift(ctx, target, actions, seen):
    mapped_srcs = target.attrs_lazy().get("mapped_srcs").value()
    built = ctx.build(mapped_srcs.keys())
    out = []
    for label, artifacts in built.items():
        mapped_src = mapped_srcs.get(label)

        outfile = "{}/{}/{}/{}".format(target.label.cell, target.label.package, target.label.name, mapped_src)
        if outfile in seen:
            continue

        if label.sub_target:
            label = "{}[{}]".format(label.raw_target(), label.sub_target[0])
        else:
            label = label.raw_target()

        if len(artifacts.artifacts()) > 0:
            copied = actions.copy_file(outfile, artifacts.artifacts()[0])
            copied = ctx.output.ensure(copied)
            artifact = {
                "artifact": copied.abs_path(),
                "label": label,
                "mapped_src": mapped_src,
            }
            out.append(artifact)

        seen[outfile] = ()
    return out

def expand_proc_macros(ctx, targets):
    target_universe = ctx.target_universe(targets).target_set()
    targets = ctx.cquery().deps(target_universe)
    targets = ctx.cquery().kind("^(rust_binary|rust_library)$", targets)

    out = {}
    for target in targets:
        attrs = target.resolved_attrs_eager(ctx)
        proc_macro = getattr(attrs, "proc_macro", False)
        if proc_macro:
            analysis = ctx.analysis(target)
            rlib = analysis.providers()[RustLinkInfo].strategies[LinkStrategy("shared")].rlib
            label = target.label.raw_target()
            out[label] = {"actual": label, "dylib": ctx.output.ensure(rlib).abs_path()}
    return out

# Returns a list of all the expanded targets including any workspaces, followed by just the workspaces
def expand_targets(ctx, targets):
    target_universe = ctx.target_universe(targets).target_set()
    kind_target_list = ctx.cquery().kind("^(rust_binary|rust_library|rust_test|alias)$", target_universe)

    # Allow targets to opt-in to being treated as rust-analyzer-compatible.
    # This is used for cross-compilation targets that apply Buck transitions to Rust rules.
    labeled_target_list = ctx.cquery().attrfilter("labels", "rust_analyzer_target", target_universe)
    expanded_targets = {t.label.raw_target(): t for t in kind_target_list + labeled_target_list}

    # Map of potential workspaces to a list of the targets that name these as potential workspaces
    possible_workspaces = {}
    for label, t in expanded_targets.items():
        workspaces = t.attrs_lazy().get("_workspaces")
        if workspaces:
            for workspace in workspaces.value():
                if not ctx.target_exists(str(workspace.raw_target())):
                    continue

                possible_workspaces.setdefault(workspace.raw_target(), []).append(label)

    active_workspaces = {}
    for workspace, candidate_deps in possible_workspaces.items():
        # FIXME: Using `cquery deps` here is not right. It will transparently look through
        # dependency edges of all types, meaning that eg build tools written in Rust and built
        # from source will show up too
        workspace_deps = {d.label.raw_target(): () for d in ctx.cquery().deps(workspace)}
        for d in candidate_deps:
            if d in workspace_deps:
                active_workspaces[workspace] = ()

                # Remove the target from the expanded targets. This is correct because we know
                # that the target will reappear later as a dep of the workspace. To understand why
                # it's necessary, consider the case where the target is a proc macro: Later doing
                # cquery deps(proc_macro + workspace) will result in the proc macro appearing twice,
                # once in its exec configuration and once in its target configuration
                # FIXME: Add a test for this. It's currently a bit hard to test because proc macros
                # in the prelude are a bit hard in general
                expanded_targets.pop(d, None)

    return dedupe(sorted(expanded_targets.keys() + active_workspaces.keys())), sorted(active_workspaces.keys())

def expand_and_resolve_impl(ctx):
    # equivalent of `flat_map`ing
    targets = [target for sublist in ctx.cli_args.targets for target in sublist]
    actions = ctx.bxl_actions().actions

    expanded_targets, workspaces = expand_targets(ctx, targets)
    queried_proc_macros = expand_proc_macros(ctx, expanded_targets)
    resolved_deps = cquery_deps(ctx, expanded_targets, workspaces, actions)

    ctx.output.print_json({
        "expanded_targets": expanded_targets,
        "queried_proc_macros": queried_proc_macros,
        "resolved_deps": resolved_deps,
    })

expand_and_resolve = bxl_main(
    impl = expand_and_resolve_impl,
    cli_args = {
        "targets": cli_args.list(cli_args.target_expr()),
    },
)
